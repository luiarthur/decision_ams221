---
title: "Bayesian Decision Theory - Decision Trees, Coherence & Dynamic Programing"
# output:
#   github_document:
#     pandoc_args: --webtex
# output: pdf_document
---

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\p}[1]{\left(#1\right)}
\newcommand{\bk}[1]{\left[#1\right]}
\newcommand{\bc}[1]{ \left\{#1\right\} }
\newcommand{\abs}[1]{ \left|#1\right| }
\newcommand{\mat}{ \begin{pmatrix} }
\newcommand{\tam}{ \end{pmatrix} }
\newcommand{\suml}{ \sum_{i=1}^n }
\newcommand{\prodl}{ \prod_{i=1}^n }
\newcommand{\ds}{ \displaystyle }
\newcommand{\df}[2]{ \frac{d#1}{d#2} }
\newcommand{\ddf}[2]{ \frac{d^2#1}{d{#2}^2} }
\newcommand{\pd}[2]{ \frac{\partial#1}{\partial#2} }
\newcommand{\pdd}[2]{\frac{\partial^2#1}{\partial{#2}^2} }
\newcommand{\N}{ \mathcal{N} }
\newcommand{\E}{ \text{E} }
\newcommand{\A}{ \mathcal{A} }
\newcommand{\X}{ \mathcal{X} }

# Decision Trees

Decision trees provide a pictorial representation of a sequential decision
problem (dynamic programming).

Refer to oil drilling example (in `notes01`).

| $\theta$ \\ $x$ | 0 | 1 |
|---|---:|---:|
| $\theta_1$ | .2 | .8 |
| $\theta_2$ | .7 | .3 |
Table: $P(X\mid\theta)$


| $\theta$ | $\theta_1$ (oil) | $\theta_2$ (no oil) |
|---|---:|---:|
|  | .6 | .4 |
Table: $\pi(\theta)$

The outcome $X = \begin{cases}
\text{presence of a certain formation} \\
\text{absence of a certain formation} \\
\end{cases}$

| $\theta$ \\ $a$ | $a_1$ (Drill) | $a_2$ (Sell) |
|---|---:|---:|
| $\theta_1$ | $-5000$  | $0$ |
| $\theta_2$ |  $2000$  | $-500$  |
Table: Loss function $\mathcal{L}(\theta, a) = -U(\theta, a)$. $C > 0$ is a sampling cost.

A decision tree has two types of nodes.

- `o` chance nodes that depend on random events
- $\square$ decision nodes that depend on actions

You start the tree from the root that is placed at the left-hand side of the paper.
The decision maker has three choices to start with. 

1. drill
2. sell
3. take the sample

INSERT GRAPH 1

$$\begin{split}
\Pr(X=1)&=\Pr(X=1\mid\theta_1) \Pr(\theta_1) + \Pr(X=1\mid\theta_2) \Pr(\theta_2)= (.8)(.6) + (.3)(.4) = .6 \\
\Pr(X=0)&=\Pr(X=0\mid\theta_1) \Pr(\theta_1) + \Pr(X=0\mid\theta_2) \Pr(\theta_2)= .4 \\
\\
\Pr(\theta_1\mid X=1)&=\Pr(X=1\mid\theta_1) \Pr(\theta_1) / \Pr(X=1) = .8\\
\Pr(\theta_2\mid X=0)&=\Pr(X=0\mid\theta_2) \Pr(\theta_2) / \Pr(X=0) = .7\\
\end{split}$$

## Example 2
Traveller considers crossing a mountain pass in the winter. The traveller can
use a car or ride a train. There are uncertainties related to the state of the road
and the possibility of an accident.

The decisions are 

- $a_1$ go by car
- $a_2$ go by train

***

- If traveller takes the train, he will be either late or on time, but he will get there.
- If traveller goes by car, the pass can be open or closed.
    - If the pass is closed, he may return safely OR have an accident.
    - If the pass is open, conditions may be good or bad.
          - if the conditions are good, he may get to the appointment late or on time
          - if the conditions are bad, he needs to consider the chances of having an accident

### Probabilities

- $\Pr(\text{pass open}) = 4/5$
- $\Pr(\text{good conditions} \mid \text{pass open}) = 2/3$
- $\Pr(\text{late} \mid \text{good conditions}) = 1/20$
- $\Pr(\text{late} \mid \text{bad conditions}) = 1/4$
- $\Pr(\text{accident} \mid \text{bad conditions}) = 1/16$
- $\Pr(\text{accident} \mid \text{pass closed}) = 1/16$
- $\Pr(\text{train late}) = 1/10$

### Utilities (usually also Negative Losses)

We consider three aspects of the problem. Utilities in parenthesis. $U \ge 0$.

- Arrival Time
    - on time (+15)
    - late (+12)
    - no arrival (0)
- Journey Quality
    - good (+5)
    - indifferent (+2)
    - bad (0)
- Possibility of Accident
    - yes (0)
    - no (+10)

INSERT TREE HERE!

## Elements of a Decision Problem

- **state of nature**: $\theta \in \Theta$
- **actions**: $a \in \A$ (aka decisions)
- **Loss function**: $L(\theta, a)$ (negative utility)
- **Statistical evidence** $X \in \X$ (data)
- **Experiment**: $e \in \mathcal{E}$ ($n \in \mathbb{N}$)

The complete scheme looks like:

INSERT GRAPH HERE

## Bets

$\theta$ is the indicator of an event. Fisher wins a tennis match against
Neyman. A bet is a ticket that will be worth $S$ (stakes) if $\theta$ occurs,
and 0 otherwise. The ticket costs $\pi_\theta S$.
$\frac{\pi_\theta}{1-\pi_\theta}$ are the betting odds in favor of $\theta$.
The payoffs for the action of buying a ticket are:

| $\theta$ | 0 | 1 |
|---|---:|---:|
| Buy bet on $\theta$ | $(1-\pi) S$ | $-\pi S$ |
| Sell bet on $\theta$ | -$(1-\pi) S$ | $\pi S$ |

## Dutch Book (Arbitrage)

Suppose a bookmaker posts the price $0.2$ for bets on the event "Fisher wins",
and the price $0.7$ for bets on "Neyman wins". Suppose you place both bets.

|  | Fisher wins | Neyman wins |
|---|---:|---:|
| Bet 1     | $0.85 S$ | $-0.25 S$ |
| Bet 2     | $-0.7 S$ | $0.3 S$   |
| Both bets | $0.1 S$  | $0.1 S$   |

You make $0.1 S$ **for sure** if you place both bets.


## Coherence

A set of betting odds is **coherent** if no combination of bets produces sure losses.

Assumptions:

1. The odds are fair. The bookmaker is willing to both sell and buy any bets.
2. There is no restriction in the number of bets that can be placed. And they
   are all equally valuable.

**Theorem**: Under assumptions 1 and 2 (above), a necessary condition for a set of prices to be coherent is that they satisfy Kolmogorov axioms.

- Axiom 1: $0 \le \pi_\theta \le 1, ~ \forall \theta$
- Axiom 2: $0 \pi_\Theta = 1$ where $\Theta$ is the sure event
- Axiom 3: If $\theta_!$ and $\theta_2$ are such that $\theta_1\theta_2 = 0$,
  then $\pi_{\theta_1} + \pi_{\theta_2} = \pi_{\theta_1 + \theta_2}$

**Proof**: See Parmigiani & Inoue p.19

## Coherent Conditional Probabilities

See Parmigiani & Inoue p.20 - 21

# Utility (Chapter 3)

- St. Peterburg Paradox
    - How do we value payoffs that are subject to uncertainty What is the fair
      price of a bet? The answer to that question is expected utility.
          - fair value `<->` expected utility

