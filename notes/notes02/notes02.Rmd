---
title: "Bayesian Decision Theory - Decision Trees, Coherence & Dynamic Programing"
# output:
#   github_document:
#     pandoc_args: --webtex
# output: pdf_document
---

\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\p}[1]{\left(#1\right)}
\newcommand{\bk}[1]{\left[#1\right]}
\newcommand{\bc}[1]{ \left\{#1\right\} }
\newcommand{\abs}[1]{ \left|#1\right| }
\newcommand{\mat}{ \begin{pmatrix} }
\newcommand{\tam}{ \end{pmatrix} }
\newcommand{\suml}{ \sum_{i=1}^n }
\newcommand{\prodl}{ \prod_{i=1}^n }
\newcommand{\ds}{ \displaystyle }
\newcommand{\df}[2]{ \frac{d#1}{d#2} }
\newcommand{\ddf}[2]{ \frac{d^2#1}{d{#2}^2} }
\newcommand{\pd}[2]{ \frac{\partial#1}{\partial#2} }
\newcommand{\pdd}[2]{\frac{\partial^2#1}{\partial{#2}^2} }
\newcommand{\N}{ \mathcal{N} }
\newcommand{\E}{ \text{E} }
\newcommand{\bs}{\textbackslash}

# Decision Trees

Decision trees provide a pictorial representation of a sequential decision
problem (dynamic programming).

Refer to oil drilling example (in `notes01`).

| $\theta \bs x$ | 0 | 1 |
|---|---|---|
| $\theta_1$ | .2 | .8 |
| $\theta_2$ | .7 | .3 |
Table: $P(X\mid\theta)$


| $\theta$ | $\theta_1$ (oil) | $\theta_2$ (no oil) |
|---|---|---|
|  | .6 | .4 |
Table: $\pi(\theta)$

The outcome $X = \begin{cases}
\text{presence of a certain formation} \\
\text{absence of a certain formation} \\
\end{cases}$

| $\theta \textbackslash a$ | $a_1$ (Drill) | $a_2$ (Sell) |
|---|---|---|
| $\theta_1$ | $-$ 5000  | 0 |
| $\theta_2$ | 2000 | $-$ 500  |
Table: Loss function $\mathcal{L}(\theta, a) = -U(\theta, a)$. $C > 0$ is a sampling cost.

A decision tree has two types of nodes.

- `o` chance nodes that depend on random events
- $\square$ decision nodes that depend on actions

You start the tree from the root that is placed at the left-hand side of the paper.
The decision maker has three choices to start with. 

1. drill
2. sell
3. take the sample

INSERT GRAPH 1

$$\begin{split}
\Pr(X=1)&=\Pr(X=1\mid\theta_1) \Pr(\theta_1) + \Pr(X=1\mid\theta_2) \Pr(\theta_2)= (.8)(.6) + (.3)(.4) = .6 \\
\Pr(X=0)&=\Pr(X=0\mid\theta_1) \Pr(\theta_1) + \Pr(X=0\mid\theta_2) \Pr(\theta_2)= .4 \\
\\
\Pr(\theta_1\mid X=1)&=\Pr(X=1\mid\theta_1) \Pr(\theta_1) / \Pr(X=1) = .8\\
\Pr(\theta_2\mid X=0)&=\Pr(X=0\mid\theta_2) \Pr(\theta_2) / \Pr(X=0) = .7\\
\end{split}$$
